services:
  whisper-webui:
    container_name: whisper-webui
    # build: .
    image: whisper-webui:latest

    volumes:
      # You can mount the container's volume paths to directory paths on your local machine.
      # Models will be stored in the `./models' directory on your machine.
      # Similarly, all output files will be stored in the `./outputs` directory.
      - ./models:/Whisper-WebUI/models
      - ./outputs:/Whisper-WebUI/outputs
      - ./configs:/Whisper-WebUI/configs

    ports:
      - "7860:7860"

    stdin_open: true
    tty: true

    entrypoint: ["python", "app.py", "--server_port", "7860", "--server_name", "0.0.0.0",  "--whisper_type", "insanely_fast_whisper",]

    # Intel Arc XPU support (no special Docker GPU configuration needed)
    # For NVIDIA GPU support, uncomment the section below:
    # See more info at : https://docs.docker.com/compose/compose-file/deploy/#driver
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [ gpu ]
